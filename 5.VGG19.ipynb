{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3756708142011531128, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9221160305\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 4222427636367449074\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\", name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6683898676\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2962721813156971485\n",
       " physical_device_desc: \"device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "import keras.callbacks as kcall\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "validation_dir = 'data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train 0\n",
      "data/train\\malignant 46000\n",
      "data/train\\normal 21736\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(train_dir):\n",
    "    print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/validation 0\n",
      "data/validation\\malignant 12176\n",
      "data/validation\\normal 5376\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(validation_dir):\n",
    "    print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67736 images belonging to 2 classes.\n",
      "Found 17552 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "\n",
    "# target_size = (height, width)\n",
    "target_size = (225, 300)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = target_size,       \n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size = target_size,        \n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    # Calculates the F score, the weighted harmonic mean of precision and recall.\n",
    "\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    # Calculates the f-measure, the harmonic mean of precision and recall.\n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intilizing variables\n",
    "output_classes = 2\n",
    "\n",
    "batch_size = 16 \n",
    "epochs = 50\n",
    "droput_rate= 0.5\n",
    "\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)\n",
    "vgg16_weights= 'pretrained-models/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = (VGG19(include_top=False, pooling='avg', weights=vgg16_weights))\n",
    "x = model.output\n",
    "# x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation=\"softmax\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "model = Model(input = model.input, output = predictions)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam_opt,\n",
    "              metrics = [\"categorical_accuracy\", fmeasure, recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2117/2116 [==============================] - 897s 424ms/step - loss: 0.7873 - categorical_accuracy: 0.7657 - fmeasure: 0.7657 - recall: 0.7657 - precision: 0.7657 - val_loss: 2.1326 - val_categorical_accuracy: 0.6945 - val_fmeasure: 0.6945 - val_recall: 0.6945 - val_precision: 0.6945\n",
      "Epoch 2/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.5010 - categorical_accuracy: 0.8677 - fmeasure: 0.8677 - recall: 0.8677 - precision: 0.8677 - val_loss: 0.4253 - val_categorical_accuracy: 0.8829 - val_fmeasure: 0.8829 - val_recall: 0.8829 - val_precision: 0.8829\n",
      "Epoch 3/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.4041 - categorical_accuracy: 0.8944 - fmeasure: 0.8944 - recall: 0.8944 - precision: 0.8944 - val_loss: 1.4474 - val_categorical_accuracy: 0.5754 - val_fmeasure: 0.5754 - val_recall: 0.5754 - val_precision: 0.5754\n",
      "Epoch 4/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.3334 - categorical_accuracy: 0.9196 - fmeasure: 0.9196 - recall: 0.9196 - precision: 0.9196 - val_loss: 0.3522 - val_categorical_accuracy: 0.9127 - val_fmeasure: 0.9127 - val_recall: 0.9127 - val_precision: 0.9127\n",
      "Epoch 5/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.2850 - categorical_accuracy: 0.9353 - fmeasure: 0.9353 - recall: 0.9353 - precision: 0.9353 - val_loss: 0.3765 - val_categorical_accuracy: 0.9200 - val_fmeasure: 0.9200 - val_recall: 0.9200 - val_precision: 0.9200\n",
      "Epoch 6/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.2365 - categorical_accuracy: 0.9500 - fmeasure: 0.9500 - recall: 0.9500 - precision: 0.9500 - val_loss: 0.2648 - val_categorical_accuracy: 0.9442 - val_fmeasure: 0.9442 - val_recall: 0.9442 - val_precision: 0.9442\n",
      "Epoch 7/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.2022 - categorical_accuracy: 0.9603 - fmeasure: 0.9603 - recall: 0.9603 - precision: 0.9603 - val_loss: 0.3199 - val_categorical_accuracy: 0.9260 - val_fmeasure: 0.9260 - val_recall: 0.9260 - val_precision: 0.9260\n",
      "Epoch 8/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.1689 - categorical_accuracy: 0.9704 - fmeasure: 0.9704 - recall: 0.9704 - precision: 0.9704 - val_loss: 0.8440 - val_categorical_accuracy: 0.8147 - val_fmeasure: 0.8147 - val_recall: 0.8147 - val_precision: 0.8147\n",
      "Epoch 9/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.1468 - categorical_accuracy: 0.9764 - fmeasure: 0.9764 - recall: 0.9764 - precision: 0.9764 - val_loss: 0.2777 - val_categorical_accuracy: 0.9463 - val_fmeasure: 0.9463 - val_recall: 0.9463 - val_precision: 0.9463\n",
      "Epoch 10/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.1304 - categorical_accuracy: 0.9814 - fmeasure: 0.9814 - recall: 0.9814 - precision: 0.9814 - val_loss: 0.3241 - val_categorical_accuracy: 0.9353 - val_fmeasure: 0.9353 - val_recall: 0.9353 - val_precision: 0.9353\n",
      "Epoch 11/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.1185 - categorical_accuracy: 0.9853 - fmeasure: 0.9853 - recall: 0.9853 - precision: 0.9853 - val_loss: 0.2943 - val_categorical_accuracy: 0.9454 - val_fmeasure: 0.9454 - val_recall: 0.9454 - val_precision: 0.9454\n",
      "Epoch 12/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.1127 - categorical_accuracy: 0.9862 - fmeasure: 0.9862 - recall: 0.9862 - precision: 0.9862 - val_loss: 0.3177 - val_categorical_accuracy: 0.9278 - val_fmeasure: 0.9278 - val_recall: 0.9278 - val_precision: 0.9278\n",
      "Epoch 13/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.1031 - categorical_accuracy: 0.9892 - fmeasure: 0.9892 - recall: 0.9892 - precision: 0.9892 - val_loss: 0.5729 - val_categorical_accuracy: 0.8764 - val_fmeasure: 0.8764 - val_recall: 0.8764 - val_precision: 0.8764\n",
      "Epoch 14/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0983 - categorical_accuracy: 0.9910 - fmeasure: 0.9910 - recall: 0.9910 - precision: 0.9910 - val_loss: 0.3273 - val_categorical_accuracy: 0.9498 - val_fmeasure: 0.9498 - val_recall: 0.9498 - val_precision: 0.9498\n",
      "Epoch 15/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0974 - categorical_accuracy: 0.9907 - fmeasure: 0.9907 - recall: 0.9907 - precision: 0.9907 - val_loss: 0.3941 - val_categorical_accuracy: 0.9404 - val_fmeasure: 0.9404 - val_recall: 0.9404 - val_precision: 0.9404\n",
      "Epoch 16/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0899 - categorical_accuracy: 0.9931 - fmeasure: 0.9931 - recall: 0.9931 - precision: 0.9931 - val_loss: 0.3382 - val_categorical_accuracy: 0.9455 - val_fmeasure: 0.9455 - val_recall: 0.9455 - val_precision: 0.9455\n",
      "Epoch 17/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0901 - categorical_accuracy: 0.9927 - fmeasure: 0.9927 - recall: 0.9927 - precision: 0.9927 - val_loss: 0.3691 - val_categorical_accuracy: 0.9464 - val_fmeasure: 0.9464 - val_recall: 0.9464 - val_precision: 0.9464\n",
      "Epoch 18/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0872 - categorical_accuracy: 0.9929 - fmeasure: 0.9929 - recall: 0.9929 - precision: 0.9929 - val_loss: 0.2959 - val_categorical_accuracy: 0.9531 - val_fmeasure: 0.9531 - val_recall: 0.9531 - val_precision: 0.9531\n",
      "Epoch 19/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0841 - categorical_accuracy: 0.9942 - fmeasure: 0.9942 - recall: 0.9942 - precision: 0.9942 - val_loss: 0.2884 - val_categorical_accuracy: 0.9514 - val_fmeasure: 0.9514 - val_recall: 0.9514 - val_precision: 0.9514\n",
      "Epoch 20/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0794 - categorical_accuracy: 0.9953 - fmeasure: 0.9953 - recall: 0.9953 - precision: 0.9953 - val_loss: 0.2855 - val_categorical_accuracy: 0.9536 - val_fmeasure: 0.9536 - val_recall: 0.9536 - val_precision: 0.9536\n",
      "Epoch 21/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0797 - categorical_accuracy: 0.9949 - fmeasure: 0.9949 - recall: 0.9949 - precision: 0.9949 - val_loss: 0.3138 - val_categorical_accuracy: 0.9554 - val_fmeasure: 0.9554 - val_recall: 0.9554 - val_precision: 0.9554\n",
      "Epoch 22/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0786 - categorical_accuracy: 0.9950 - fmeasure: 0.9950 - recall: 0.9950 - precision: 0.9950 - val_loss: 0.7643 - val_categorical_accuracy: 0.8739 - val_fmeasure: 0.8739 - val_recall: 0.8739 - val_precision: 0.8739\n",
      "Epoch 23/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0761 - categorical_accuracy: 0.9955 - fmeasure: 0.9955 - recall: 0.9955 - precision: 0.9955 - val_loss: 0.4021 - val_categorical_accuracy: 0.9470 - val_fmeasure: 0.9470 - val_recall: 0.9470 - val_precision: 0.9470\n",
      "Epoch 24/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0740 - categorical_accuracy: 0.9959 - fmeasure: 0.9959 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.2759 - val_categorical_accuracy: 0.9578 - val_fmeasure: 0.9578 - val_recall: 0.9578 - val_precision: 0.9578\n",
      "Epoch 25/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0722 - categorical_accuracy: 0.9962 - fmeasure: 0.9962 - recall: 0.9962 - precision: 0.9962 - val_loss: 0.3237 - val_categorical_accuracy: 0.9536 - val_fmeasure: 0.9536 - val_recall: 0.9536 - val_precision: 0.9536\n",
      "Epoch 26/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0712 - categorical_accuracy: 0.9966 - fmeasure: 0.9966 - recall: 0.9966 - precision: 0.9966 - val_loss: 0.2798 - val_categorical_accuracy: 0.9613 - val_fmeasure: 0.9613 - val_recall: 0.9613 - val_precision: 0.9613\n",
      "Epoch 27/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0701 - categorical_accuracy: 0.9967 - fmeasure: 0.9967 - recall: 0.9967 - precision: 0.9967 - val_loss: 0.2941 - val_categorical_accuracy: 0.9629 - val_fmeasure: 0.9629 - val_recall: 0.9629 - val_precision: 0.9629\n",
      "Epoch 28/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0677 - categorical_accuracy: 0.9974 - fmeasure: 0.9974 - recall: 0.9974 - precision: 0.9974 - val_loss: 0.3769 - val_categorical_accuracy: 0.9500 - val_fmeasure: 0.9500 - val_recall: 0.9500 - val_precision: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0695 - categorical_accuracy: 0.9964 - fmeasure: 0.9964 - recall: 0.9964 - precision: 0.9964 - val_loss: 0.2916 - val_categorical_accuracy: 0.9568 - val_fmeasure: 0.9568 - val_recall: 0.9568 - val_precision: 0.9568\n",
      "Epoch 30/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0671 - categorical_accuracy: 0.9967 - fmeasure: 0.9967 - recall: 0.9967 - precision: 0.9967 - val_loss: 0.3046 - val_categorical_accuracy: 0.9543 - val_fmeasure: 0.9543 - val_recall: 0.9543 - val_precision: 0.9543\n",
      "Epoch 31/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0639 - categorical_accuracy: 0.9979 - fmeasure: 0.9979 - recall: 0.9979 - precision: 0.9979 - val_loss: 0.3021 - val_categorical_accuracy: 0.9602 - val_fmeasure: 0.9602 - val_recall: 0.9602 - val_precision: 0.9602\n",
      "Epoch 32/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0643 - categorical_accuracy: 0.9975 - fmeasure: 0.9975 - recall: 0.9975 - precision: 0.9975 - val_loss: 0.2857 - val_categorical_accuracy: 0.9601 - val_fmeasure: 0.9601 - val_recall: 0.9601 - val_precision: 0.9601\n",
      "Epoch 33/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0620 - categorical_accuracy: 0.9977 - fmeasure: 0.9977 - recall: 0.9977 - precision: 0.9977 - val_loss: 0.3571 - val_categorical_accuracy: 0.9441 - val_fmeasure: 0.9441 - val_recall: 0.9441 - val_precision: 0.9441\n",
      "Epoch 34/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0613 - categorical_accuracy: 0.9978 - fmeasure: 0.9978 - recall: 0.9978 - precision: 0.9978 - val_loss: 0.3382 - val_categorical_accuracy: 0.9531 - val_fmeasure: 0.9531 - val_recall: 0.9531 - val_precision: 0.9531\n",
      "Epoch 35/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0597 - categorical_accuracy: 0.9982 - fmeasure: 0.9982 - recall: 0.9982 - precision: 0.9982 - val_loss: 0.2863 - val_categorical_accuracy: 0.9559 - val_fmeasure: 0.9559 - val_recall: 0.9559 - val_precision: 0.9559\n",
      "Epoch 36/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0602 - categorical_accuracy: 0.9977 - fmeasure: 0.9977 - recall: 0.9977 - precision: 0.9977 - val_loss: 0.2736 - val_categorical_accuracy: 0.9630 - val_fmeasure: 0.9630 - val_recall: 0.9630 - val_precision: 0.9630\n",
      "Epoch 37/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0585 - categorical_accuracy: 0.9981 - fmeasure: 0.9981 - recall: 0.9981 - precision: 0.9981 - val_loss: 0.3084 - val_categorical_accuracy: 0.9568 - val_fmeasure: 0.9568 - val_recall: 0.9568 - val_precision: 0.9568\n",
      "Epoch 38/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0582 - categorical_accuracy: 0.9981 - fmeasure: 0.9981 - recall: 0.9981 - precision: 0.9981 - val_loss: 0.3244 - val_categorical_accuracy: 0.9536 - val_fmeasure: 0.9536 - val_recall: 0.9536 - val_precision: 0.9536\n",
      "Epoch 39/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0564 - categorical_accuracy: 0.9985 - fmeasure: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 0.5293 - val_categorical_accuracy: 0.9261 - val_fmeasure: 0.9261 - val_recall: 0.9261 - val_precision: 0.9261\n",
      "Epoch 40/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0558 - categorical_accuracy: 0.9984 - fmeasure: 0.9984 - recall: 0.9984 - precision: 0.9984 - val_loss: 0.2719 - val_categorical_accuracy: 0.9655 - val_fmeasure: 0.9655 - val_recall: 0.9655 - val_precision: 0.9655\n",
      "Epoch 41/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0557 - categorical_accuracy: 0.9981 - fmeasure: 0.9981 - recall: 0.9981 - precision: 0.9981 - val_loss: 0.2753 - val_categorical_accuracy: 0.9631 - val_fmeasure: 0.9631 - val_recall: 0.9631 - val_precision: 0.9631\n",
      "Epoch 42/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0544 - categorical_accuracy: 0.9985 - fmeasure: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 0.3947 - val_categorical_accuracy: 0.9483 - val_fmeasure: 0.9483 - val_recall: 0.9483 - val_precision: 0.9483\n",
      "Epoch 43/50\n",
      "2117/2116 [==============================] - 889s 420ms/step - loss: 0.0539 - categorical_accuracy: 0.9985 - fmeasure: 0.9985 - recall: 0.9985 - precision: 0.9985 - val_loss: 0.3481 - val_categorical_accuracy: 0.9571 - val_fmeasure: 0.9571 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 44/50\n",
      " 974/2116 [============>.................] - ETA: 7:20 - loss: 0.0520 - categorical_accuracy: 0.9987 - fmeasure: 0.9987 - recall: 0.9987 - precision: 0.9987"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Test Score: ', score[0])\n",
    "print ('Test Accuracy: ',score[1])\n",
    "print ('fmeasure: ', score[2])\n",
    "print ('Recall: ', score[3])\n",
    "print ('Precision: ', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"categorical_accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_categorical_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = validation_generator.filenames\n",
    "truth = validation_generator.classes\n",
    "label = validation_generator.class_indices\n",
    "indexlabel = dict((value, key) for key, value in label.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size, verbose=1)\n",
    "predict_class = np.argmax(predicts, axis=1)\n",
    "errors = np.where(predict_class != truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(truth,predict_class)\n",
    "\n",
    "labels = []\n",
    "for k,v in indexlabel.items():\n",
    "    labels.append(v)\n",
    "    \n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig('plots/5.VGG19-CM.png', bbox_inches='tight', dpi = 100)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm, classes=labels,\n",
    "                      title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = confusion_matrix(truth,predict_class)\n",
    "total1=sum(sum(cm1))\n",
    "\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "Specificity = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "print('Specificity : ', Specificity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = predicts\n",
    "y_pred_probabilities=y_pred\n",
    "\n",
    "y_pred = np.argmax(y_pred,axis = 1) \n",
    "y_actual = validation_generator.classes\n",
    "\n",
    "classnames=[]\n",
    "for classname in validation_generator.class_indices:\n",
    "    classnames.append(classname)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_actual, y_pred) \n",
    "print(confusion_mtx)\n",
    "target_names = classnames\n",
    "print(classification_report(y_actual, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "y_true = valid_labels\n",
    "y_score = predicts.argmax(axis=1)  # y_predicted\n",
    "\n",
    "\n",
    "th = 0.3\n",
    "\n",
    "acc = accuracy_score(y_true, y_score > th)\n",
    "prec = precision_score(y_true, y_score > th)\n",
    "f1 = f1_score(y_true, y_score > th)\n",
    "recall = recall_score(y_true, y_score > th)\n",
    "\n",
    "print('Accuracy:  {:.3f}'.format(acc))\n",
    "print('Precision: {:.3f}'.format(prec))\n",
    "print('Recall:    {:.3f}'.format(recall))\n",
    "print('F1:        {:.3f}'.format(f1))\n",
    "print('Classification report')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_score > th).ravel()\n",
    "\n",
    "print('                      Confusion matrix')\n",
    "print('                       True condition')\n",
    "print('                      Positive Negative      Sum')\n",
    "print('Predicted | Positive  {:8} {:8} {:8}'.format(tp, fp, tp + fp))\n",
    "print('condition | Negative  {:8} {:8} {:8}'.format(fn, tn, fn + tn))\n",
    "print('                 Sum  {:8} {:8} {:8}'.format(tp + fn, fp + tn, tp + fp + fn + tn))\n",
    "print(' ')\n",
    "print('Sensitivity: {:.3f}'.format(tp/(tp+fn)))\n",
    "print('Specificity: {:.3f}'.format(tn/(tn+fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "valid_labels = validation_generator.classes\n",
    "fpr, tpr, thresholds = roc_curve(valid_labels, predicts.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,7))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve for VGG19 (area = {:.3f})'.format(auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC curve)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds})\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "y_true = valid_labels\n",
    "y_score = predicts.argmax(axis=1)  # y_predicted\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], '--')\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve   AUC = {:.3f}'.format(auc))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, 1-fpr, label = 'specificity')\n",
    "plt.plot(thresholds, tpr, label = 'sensitivity')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Threshold value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(validation_generator.classes, np.argmax(predicts, axis=1))\n",
    "average_precision = average_precision_score(validation_generator.classes, np.argmax(predicts, axis=1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/5.VGG19-Model.h5')\n",
    "model.save_weights('models/5.VGG19-Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"models/5.VGG19-Model.h5\")\n",
    "model.load_weights(\"models/VGG19-Weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
